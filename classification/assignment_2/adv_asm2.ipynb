{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Phần Nâng cao - Cải tiến mô hình\n",
    "\n",
    "Phần này học viên sẽ tự thực hiện việc cải tiến kết quả dự đoán của mô hình để cho ra kết quả tốt hơn ở phần trước. Tức là điểm số trên Kaggle của học viên phải vượt qua **0.8246 (Public Score), > top 50%**. Một vài phương pháp được đề xuất để học viên lựa chọn là:\n",
    "\n",
    "- Thay đổi phương pháp lựa chọn đặc trưng để chọn ra bộ đặc trưng tốt hơn\n",
    "\n",
    "- Sử dụng phương pháp khác để xử lý vấn đề mất cân bằng dữ liệu\n",
    "\n",
    "- Sử dụng các mô hình học máy khác hoặc các kỹ thuật kết hợp mô hình nâng cao \n",
    "\n",
    "- Tập trung vào việc cải tiến các mô hình Boosting\n",
    "\n",
    "- Tinh chỉnh các tham số của mô hình\n",
    "\n",
    "- Sử dụng các kỹ thuật K-Fold hoặc chia nhỏ tập train để tránh hiện tượng Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load các package cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "test_id = test['ID']\n",
    "X_train = train.drop('ID', axis=1)\n",
    "X_test = test.drop('ID', axis=1)\n",
    "\n",
    "X_train = X_train.drop('TARGET', axis=1)\n",
    "y_train = train['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khám phá dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76020, 369), (76020,), (75818, 369))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var3', 'var15', 'imp_ent_var16_ult1', 'imp_op_var39_comer_ult1',\n",
       "       'imp_op_var39_comer_ult3', 'imp_op_var40_comer_ult1',\n",
       "       'imp_op_var40_comer_ult3', 'imp_op_var40_efect_ult1',\n",
       "       'imp_op_var40_efect_ult3', 'imp_op_var40_ult1',\n",
       "       ...\n",
       "       'saldo_medio_var29_ult3', 'saldo_medio_var33_hace2',\n",
       "       'saldo_medio_var33_hace3', 'saldo_medio_var33_ult1',\n",
       "       'saldo_medio_var33_ult3', 'saldo_medio_var44_hace2',\n",
       "       'saldo_medio_var44_hace3', 'saldo_medio_var44_ult1',\n",
       "       'saldo_medio_var44_ult3', 'var38'],\n",
       "      dtype='object', length=369)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "numerical_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_features = X_train.select_dtypes(include=[np.object]).columns\n",
    "categories_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73012\n",
       "1     3008\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0395685345961589"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = y_train.value_counts()[1] / y_train.value_counts().sum()\n",
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi khám phá nhận thấy:\n",
    "- Dữ liệu toàn bộ là các dữ liệu số\n",
    "- Không có dữ liệu bị khuyết\n",
    "- Là imbalanced data do có 73012 target là 0 trong khi chỉ có 3008 target là 1 chiếm tỉ lệ 3,9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loại bỏ các biến trùng, hoặc gần giống nhau, hoặc có tương quan cao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from feature_engine.selection import (\n",
    "    DropConstantFeatures,\n",
    "    DropDuplicateFeatures,\n",
    "    SmartCorrelatedSelection,\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=0.998)),\n",
    "    ('duplicated', DropDuplicateFeatures()),\n",
    "    ('correlation', SmartCorrelatedSelection(selection_method='variance')),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train)\n",
    "X_train = pipe.transform(X_train)\n",
    "X_test = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76020, 81), (75818, 81))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all features columns\n",
    "selected_features = {}\n",
    "#selected_features['all_features'] = X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_selection(X_train, y_train):\n",
    "    from sklearn.ensemble import ExtraTreesClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from feature_engine.selection import RecursiveFeatureElimination\n",
    "    from feature_engine.selection import RecursiveFeatureAddition\n",
    "    #All features\n",
    "    selected_features = {}\n",
    "    #selected_features['all_features'] = X_train.columns.to_list()\n",
    "    #print('All features: ', len(selected_features['all_features']))\n",
    "    \n",
    "    # ExtraTreesClassifier\n",
    "    # clf = ExtraTreesClassifier(random_state=0)\n",
    "    # clf.fit(X_train, y_train)\n",
    "    # fs = SelectFromModel(estimator=clf , prefit=True)\n",
    "    # selected\n",
    "    # _features['extra_trees_classifier'] = X_train.columns[fs.get_support()].tolist()\n",
    "    \n",
    "    # ExtraTreesClassifier\n",
    "    sel = SelectFromModel(ExtraTreesClassifier(random_state=0))\n",
    "    sel.fit(X_train, y_train)\n",
    "    selected_features['extra_trees_classifier'] = X_train.columns[sel.get_support()].tolist()\n",
    "    print('{} features selected by ExtraTreesClassifier'.format(len(selected_features['extra_trees_classifier'])))\n",
    "    \n",
    "    # RandomForestClassifier\n",
    "    sel = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=10))\n",
    "    sel.fit(X_train, y_train)\n",
    "    selected_features['random_forest_classifier'] = X_train.columns[sel.get_support()].tolist()\n",
    "    print('{} features selected by RandomForestClassifier'.format(len(selected_features['random_forest_classifier'])))\n",
    "\n",
    "    # RecursiveFeatureElimination\n",
    "    model = GradientBoostingClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=2,\n",
    "    random_state=10)\n",
    "    sel = RecursiveFeatureElimination(\n",
    "        variables=None, # automatically evaluate all numerical variables\n",
    "        estimator = model, # the ML model\n",
    "        scoring = 'roc_auc', # the metric we want to evalute\n",
    "        threshold = 0.0005, # the maximum performance drop allowed to remove a feature\n",
    "        cv=2,) # cross-validation\n",
    "    sel.fit(X_train, y_train)\n",
    "    selected_features['recursive_feature_elimination'] = sel.transform(X_train).columns.tolist()\n",
    "    print('{} features selected by RecursiveFeatureElimination'.format(len(selected_features['recursive_feature_elimination'])))\n",
    "    \n",
    "    # RecursiveFeatureAddition\n",
    "    model = GradientBoostingClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=2,\n",
    "    random_state=10)\n",
    "    # Setup the RFA selector\n",
    "    sel = RecursiveFeatureAddition(\n",
    "        variables=None,  # automatically evaluate all numerical variables\n",
    "        estimator=model,  # the ML model\n",
    "        scoring='roc_auc',  # the metric we want to evalute\n",
    "        threshold=0.0005,  # the minimum performance increase needed to select a feature\n",
    "        cv=2)  # cross-validation\n",
    "    sel.fit(X_train, y_train)\n",
    "    selected_features['recursive_feature_addition'] = sel.transform(X_train).columns.tolist()\n",
    "    print('{} features selected by RecursiveFeatureAddition'.format(len(selected_features['recursive_feature_addition'])))\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 features selected by ExtraTreesClassifier\n",
      "12 features selected by RandomForestClassifier\n",
      "6 features selected by RecursiveFeatureElimination\n",
      "4 features selected by RecursiveFeatureAddition\n"
     ]
    }
   ],
   "source": [
    "selected_features = features_selection(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value:  ['var15', 'saldo_var5', 'saldo_var30', 'saldo_var42', 'var36', 'num_var22_hace2', 'num_var22_hace3', 'num_var22_ult3', 'num_var45_hace3', 'num_var45_ult3', 'saldo_medio_var5_hace2', 'saldo_medio_var5_hace3', 'saldo_medio_var5_ult3', 'var38']\n",
      "Value:  ['var15', 'saldo_var5', 'saldo_var30', 'saldo_var42', 'num_var22_hace2', 'num_var22_ult3', 'num_var45_hace3', 'num_var45_ult3', 'saldo_medio_var5_hace2', 'saldo_medio_var5_hace3', 'saldo_medio_var5_ult3', 'var38']\n",
      "Value:  ['var15', 'imp_op_var39_efect_ult3', 'saldo_var30', 'num_var22_ult1', 'saldo_medio_var5_hace3', 'var38']\n",
      "Value:  ['var15', 'saldo_var30', 'saldo_medio_var5_hace3', 'var38']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data = {}\n",
    "\n",
    "for key, value in selected_features.items():\n",
    "    print('Value: ', value)\n",
    "    scaled_data[key+'_scaled'] = {'train': scaler.fit_transform(X_train[value]), 'test': scaler.transform(X_test[value])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.under_sampling import (\n",
    "    RandomUnderSampler,\n",
    "    CondensedNearestNeighbour,\n",
    "    TomekLinks,\n",
    "    OneSidedSelection,\n",
    "    EditedNearestNeighbours,\n",
    "    RepeatedEditedNearestNeighbours,\n",
    "    AllKNN,\n",
    "    NeighbourhoodCleaningRule,\n",
    "    NearMiss,\n",
    "    InstanceHardnessThreshold\n",
    ")\n",
    "\n",
    "undersampler_dict = {\n",
    "    'random': RandomUnderSampler(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        replacement=False),\n",
    "\n",
    "    'tomek': TomekLinks(\n",
    "        sampling_strategy='auto',\n",
    "        n_jobs=n_jobs),\n",
    "\n",
    "    'enn': EditedNearestNeighbours(\n",
    "        sampling_strategy='auto',\n",
    "        n_neighbors=3,\n",
    "        kind_sel='all',\n",
    "        n_jobs=n_jobs),\n",
    "\n",
    "    'allknn': AllKNN(\n",
    "        sampling_strategy='auto',\n",
    "        n_neighbors=3,\n",
    "        kind_sel='all',\n",
    "        n_jobs=n_jobs),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import (\n",
    "    RandomOverSampler,\n",
    "    SMOTE,\n",
    "    ADASYN,\n",
    "    BorderlineSMOTE,\n",
    "    SVMSMOTE,\n",
    ")\n",
    "\n",
    "oversampler_dict = {\n",
    "    'smote': SMOTE(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        k_neighbors=5,\n",
    "        n_jobs=n_jobs),\n",
    "\n",
    "    'border1': BorderlineSMOTE(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        k_neighbors=5,\n",
    "        m_neighbors=10,\n",
    "        kind='borderline-1',\n",
    "        n_jobs=n_jobs),\n",
    "\n",
    "    'adasyn': ADASYN(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        n_neighbors=5,\n",
    "        n_jobs=n_jobs),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-Under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "combined_sampler_dict = {\n",
    "    'smenn': SMOTEENN(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        smote=SMOTE(sampling_strategy='auto', random_state=0, k_neighbors=5),\n",
    "        enn=EditedNearestNeighbours(\n",
    "            sampling_strategy='auto', n_neighbors=3, kind_sel='all'),\n",
    "        n_jobs=n_jobs),\n",
    "\n",
    "    'smtomek': SMOTETomek(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        smote=SMOTE(sampling_strategy='auto', random_state=0, k_neighbors=5),\n",
    "        tomek=TomekLinks(sampling_strategy='all'),\n",
    "        n_jobs=n_jobs),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huấn luyện các mô hình cơ sở"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = {\n",
    "    'logistic_regression': LogisticRegression(),\n",
    "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=10),\n",
    "    'k_nearest_neighbors': KNeighborsClassifier(n_neighbors=2),\n",
    "    'decision_tree': DecisionTreeClassifier(),\n",
    "    'adaboost_classifier': AdaBoostClassifier(),\n",
    "    'neural_network': MLPClassifier(hidden_layer_sizes=(10, 5, ), activation='logistic', max_iter=300),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_model(model, X_train, y_train, resampler):\n",
    "    pipeline = make_pipeline(resampler, model)\n",
    "    cv_results =  cross_validate(pipeline, \n",
    "                                 X_train, \n",
    "                                 y_train, \n",
    "                                 cv=3, \n",
    "                                 scoring='roc_auc', \n",
    "                                 n_jobs=n_jobs,)\n",
    "    return cv_results['test_score'].mean(), cv_results['test_score'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model:  logistic_regression\n",
      "========================================\n",
      "__Dataset: extra_trees_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.764 +/- 0.003\n",
      "________Max AUC: 0.764 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.763 +/- 0.001\n",
      "________Max AUC: 0.764 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: enn\n",
      "________AUC: 0.764 +/- 0.001\n",
      "________Max AUC: 0.764 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.764 +/- 0.001\n",
      "________Max AUC: 0.764 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smote\n",
      "________AUC: 0.770 +/- 0.002\n",
      "________Max AUC: 0.770 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: smote)\n",
      "__Resampler: border1\n",
      "________AUC: 0.775 +/- 0.001\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.771 +/- 0.002\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.770 +/- 0.002\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.770 +/- 0.002\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Dataset: random_forest_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.751 +/- 0.003\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.756 +/- 0.008\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: enn\n",
      "________AUC: 0.756 +/- 0.008\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.756 +/- 0.008\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: smote\n",
      "________AUC: 0.757 +/- 0.003\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: border1\n",
      "________AUC: 0.770 +/- 0.003\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.756 +/- 0.003\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.752 +/- 0.002\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.757 +/- 0.003\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Dataset: recursive_feature_elimination_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.747 +/- 0.004\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.749 +/- 0.008\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: enn\n",
      "________AUC: 0.748 +/- 0.008\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.747 +/- 0.008\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: smote\n",
      "________AUC: 0.752 +/- 0.004\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: border1\n",
      "________AUC: 0.761 +/- 0.003\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.751 +/- 0.003\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.749 +/- 0.004\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.752 +/- 0.003\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Dataset: recursive_feature_addition_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.748 +/- 0.003\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.750 +/- 0.008\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: enn\n",
      "________AUC: 0.749 +/- 0.008\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.749 +/- 0.008\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: smote\n",
      "________AUC: 0.752 +/- 0.003\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: border1\n",
      "________AUC: 0.763 +/- 0.005\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.752 +/- 0.003\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.751 +/- 0.004\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.752 +/- 0.003\n",
      "________Max AUC: 0.775 (model: logistic_regression, dataset: extra_trees_classifier_scaled, resampler: border1)\n",
      "========================================\n",
      "Model:  random_forest\n",
      "========================================\n",
      "__Dataset: extra_trees_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.799 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.757 +/- 0.008\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: enn\n",
      "________AUC: 0.770 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.774 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smote\n",
      "________AUC: 0.765 +/- 0.008\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: border1\n",
      "________AUC: 0.771 +/- 0.003\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.760 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.716 +/- 0.003\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.766 +/- 0.010\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Dataset: random_forest_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.798 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.754 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: enn\n",
      "________AUC: 0.767 +/- 0.010\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.766 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smote\n",
      "________AUC: 0.757 +/- 0.008\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: border1\n",
      "________AUC: 0.764 +/- 0.008\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.756 +/- 0.010\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.707 +/- 0.001\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.757 +/- 0.008\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Dataset: recursive_feature_elimination_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.793 +/- 0.002\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.743 +/- 0.004\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: enn\n",
      "________AUC: 0.753 +/- 0.004\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.759 +/- 0.004\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smote\n",
      "________AUC: 0.776 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: border1\n",
      "________AUC: 0.779 +/- 0.010\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.772 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.696 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.780 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Dataset: recursive_feature_addition_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.784 +/- 0.003\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.732 +/- 0.004\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: enn\n",
      "________AUC: 0.745 +/- 0.004\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.745 +/- 0.005\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smote\n",
      "________AUC: 0.746 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: border1\n",
      "________AUC: 0.754 +/- 0.010\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.746 +/- 0.004\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.708 +/- 0.009\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.753 +/- 0.005\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "========================================\n",
      "Model:  k_nearest_neighbors\n",
      "========================================\n",
      "__Dataset: extra_trees_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.693 +/- 0.004\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.566 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: enn\n",
      "________AUC: 0.608 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.610 +/- 0.008\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smote\n",
      "________AUC: 0.612 +/- 0.004\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: border1\n",
      "________AUC: 0.607 +/- 0.002\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.609 +/- 0.004\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.588 +/- 0.002\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.616 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Dataset: random_forest_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.684 +/- 0.011\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.564 +/- 0.008\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: enn\n",
      "________AUC: 0.597 +/- 0.008\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.598 +/- 0.011\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smote\n",
      "________AUC: 0.607 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: border1\n",
      "________AUC: 0.600 +/- 0.005\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.609 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.579 +/- 0.004\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.610 +/- 0.008\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Dataset: recursive_feature_elimination_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.673 +/- 0.005\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.563 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: enn\n",
      "________AUC: 0.591 +/- 0.012\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.594 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smote\n",
      "________AUC: 0.614 +/- 0.005\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: border1\n",
      "________AUC: 0.610 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.618 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.584 +/- 0.002\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.620 +/- 0.004\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Dataset: recursive_feature_addition_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.675 +/- 0.001\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.558 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: enn\n",
      "________AUC: 0.592 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.595 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smote\n",
      "________AUC: 0.624 +/- 0.010\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: border1\n",
      "________AUC: 0.616 +/- 0.012\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.625 +/- 0.012\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.582 +/- 0.004\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.624 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "========================================\n",
      "Model:  decision_tree\n",
      "========================================\n",
      "__Dataset: extra_trees_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.676 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.578 +/- 0.005\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: enn\n",
      "________AUC: 0.609 +/- 0.011\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.620 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smote\n",
      "________AUC: 0.618 +/- 0.010\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: border1\n",
      "________AUC: 0.614 +/- 0.005\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.614 +/- 0.008\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.572 +/- 0.001\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.623 +/- 0.005\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Dataset: random_forest_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.678 +/- 0.004\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.572 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: enn\n",
      "________AUC: 0.599 +/- 0.005\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.608 +/- 0.009\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smote\n",
      "________AUC: 0.617 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: border1\n",
      "________AUC: 0.614 +/- 0.005\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.612 +/- 0.009\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.575 +/- 0.002\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.624 +/- 0.003\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Dataset: recursive_feature_elimination_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.675 +/- 0.002\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.585 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: enn\n",
      "________AUC: 0.605 +/- 0.001\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.608 +/- 0.003\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smote\n",
      "________AUC: 0.636 +/- 0.003\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: border1\n",
      "________AUC: 0.634 +/- 0.007\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.638 +/- 0.003\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.578 +/- 0.001\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.647 +/- 0.006\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Dataset: recursive_feature_addition_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.670 +/- 0.001\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.585 +/- 0.008\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: enn\n",
      "________AUC: 0.602 +/- 0.002\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.608 +/- 0.003\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smote\n",
      "________AUC: 0.634 +/- 0.005\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: border1\n",
      "________AUC: 0.631 +/- 0.005\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.632 +/- 0.002\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.580 +/- 0.001\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.645 +/- 0.005\n",
      "________Max AUC: 0.799 (model: random_forest, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "========================================\n",
      "Model:  adaboost_classifier\n",
      "========================================\n",
      "__Dataset: extra_trees_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.818 +/- 0.004\n",
      "________Max AUC: 0.818 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.823 +/- 0.004\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.823 +/- 0.006\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.822 +/- 0.006\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: smote\n",
      "________AUC: 0.817 +/- 0.006\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: border1\n",
      "________AUC: 0.815 +/- 0.004\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.816 +/- 0.007\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.809 +/- 0.003\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.816 +/- 0.006\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Dataset: random_forest_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.819 +/- 0.005\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.823 +/- 0.005\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: enn\n",
      "________AUC: 0.824 +/- 0.005\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.823 +/- 0.004\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: smote\n",
      "________AUC: 0.813 +/- 0.007\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: border1\n",
      "________AUC: 0.815 +/- 0.004\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.811 +/- 0.007\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.800 +/- 0.004\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.812 +/- 0.006\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Dataset: recursive_feature_elimination_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.821 +/- 0.003\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.825 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.825 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.824 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.814 +/- 0.001\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.815 +/- 0.003\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.816 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.799 +/- 0.003\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.814 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Dataset: recursive_feature_addition_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.816 +/- 0.005\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.821 +/- 0.004\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.820 +/- 0.004\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.820 +/- 0.003\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.812 +/- 0.003\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.811 +/- 0.001\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.813 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.795 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.813 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "========================================\n",
      "Model:  neural_network\n",
      "========================================\n",
      "__Dataset: extra_trees_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.805 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.804 +/- 0.001\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.804 +/- 0.001\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.804 +/- 0.001\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.814 +/- 0.004\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.808 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.813 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.809 +/- 0.003\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.814 +/- 0.001\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Dataset: random_forest_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.776 +/- 0.010\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.791 +/- 0.005\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.794 +/- 0.003\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.793 +/- 0.007\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.805 +/- 0.004\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.798 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.809 +/- 0.005\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.798 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.806 +/- 0.004\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Dataset: recursive_feature_elimination_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.753 +/- 0.004\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.775 +/- 0.007\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.774 +/- 0.009\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.779 +/- 0.011\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.803 +/- 0.005\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.800 +/- 0.004\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.802 +/- 0.003\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.792 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.802 +/- 0.005\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Dataset: recursive_feature_addition_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.759 +/- 0.013\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.774 +/- 0.006\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.779 +/- 0.008\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.778 +/- 0.006\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.799 +/- 0.004\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.796 +/- 0.004\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.798 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.791 +/- 0.003\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.798 +/- 0.006\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_dict = {}\n",
    "std_dict = {}\n",
    "\n",
    "max_score = 0\n",
    "max_model_name = ''\n",
    "max_dataset_name = ''\n",
    "max_resampler_name = ''\n",
    "\n",
    "for model_name, model in base_models.items():\n",
    "    results_dict[model_name] = {}\n",
    "    std_dict[model_name] = {}\n",
    "    print(\"=\"*40)\n",
    "    print('Model: ', model_name)\n",
    "    print(\"=\"*40)\n",
    "    for dataset_name, dataset in scaled_data.items():\n",
    "        \n",
    "        results_dict[model_name][dataset_name] = {}\n",
    "        std_dict[model_name][dataset_name] = {}\n",
    "        \n",
    "        print('__Dataset: {}'.format(dataset_name))\n",
    "        \n",
    "        X_train = dataset['train']\n",
    "        \n",
    "        for resampler_name, resampler in undersampler_dict.items():\n",
    "            print('__Resampler: {}'.format(resampler_name))\n",
    "            auc, auc_std = run_model(model, X_train, y_train, resampler)\n",
    "            print('________AUC: {:.3f} +/- {:.3f}'.format(auc, auc_std))\n",
    "            results_dict[model_name][dataset_name][resampler_name] = auc\n",
    "            std_dict[model_name][dataset_name][resampler_name] = auc_std\n",
    "            if auc > max_score:\n",
    "                max_score = auc\n",
    "                max_model_name = model_name\n",
    "                max_dataset_name = dataset_name\n",
    "                max_resampler_name = resampler_name\n",
    "            print('________Max AUC: {:.3f} (model: {}, dataset: {}, resampler: {})'.format(max_score, max_model_name, max_dataset_name, max_resampler_name))\n",
    "    \n",
    "        for resampler_name, resampler in oversampler_dict.items():\n",
    "            print('__Resampler: {}'.format(resampler_name))\n",
    "            auc, auc_std = run_model(model, X_train, y_train, resampler)\n",
    "            print('________AUC: {:.3f} +/- {:.3f}'.format(auc, auc_std))\n",
    "            results_dict[model_name][dataset_name][resampler_name] = auc\n",
    "            std_dict[model_name][dataset_name][resampler_name] = auc_std\n",
    "            if auc > max_score:\n",
    "                max_score = auc\n",
    "                max_model_name = model_name\n",
    "                max_dataset_name = dataset_name\n",
    "                max_resampler_name = resampler_name\n",
    "            print('________Max AUC: {:.3f} (model: {}, dataset: {}, resampler: {})'.format(max_score, max_model_name, max_dataset_name, max_resampler_name))\n",
    "        \n",
    "        for resampler_name, resampler in combined_sampler_dict.items():\n",
    "            print('__Resampler: {}'.format(resampler_name))\n",
    "            auc, auc_std = run_model(model, X_train, y_train, resampler)\n",
    "            print('________AUC: {:.3f} +/- {:.3f}'.format(auc, auc_std))\n",
    "            results_dict[model_name][dataset_name][resampler_name] = auc\n",
    "            std_dict[model_name][dataset_name][resampler_name] = auc_std\n",
    "            if auc > max_score:\n",
    "                max_score = auc\n",
    "                max_model_name = model_name\n",
    "                max_dataset_name = dataset_name\n",
    "                max_resampler_name = resampler_name\n",
    "            print('________Max AUC: {:.3f} (model: {}, dataset: {}, resampler: {})'.format(max_score, max_model_name, max_dataset_name, max_resampler_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def flatten_dict(d, parent_key='', sep='.'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "flatten_result = flatten_dict(results_dict)\n",
    "result_pd = pd.DataFrame.from_dict(flatten_result, orient='index')\n",
    "result_pd.columns = ['AUC']\n",
    "result_pd.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adaboost_classifier.recursive_feature_elimination_scaled.tomek</th>\n",
       "      <td>0.825461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost_classifier.recursive_feature_elimination_scaled.enn</th>\n",
       "      <td>0.825150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost_classifier.recursive_feature_elimination_scaled.allknn</th>\n",
       "      <td>0.824081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost_classifier.random_forest_classifier_scaled.enn</th>\n",
       "      <td>0.823706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost_classifier.random_forest_classifier_scaled.allknn</th>\n",
       "      <td>0.823046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost_classifier.extra_trees_classifier_scaled.enn</th>\n",
       "      <td>0.822949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost_classifier.extra_trees_classifier_scaled.tomek</th>\n",
       "      <td>0.822921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost_classifier.random_forest_classifier_scaled.tomek</th>\n",
       "      <td>0.822868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost_classifier.extra_trees_classifier_scaled.allknn</th>\n",
       "      <td>0.822271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost_classifier.recursive_feature_elimination_scaled.random</th>\n",
       "      <td>0.820927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         AUC\n",
       "adaboost_classifier.recursive_feature_eliminati...  0.825461\n",
       "adaboost_classifier.recursive_feature_eliminati...  0.825150\n",
       "adaboost_classifier.recursive_feature_eliminati...  0.824081\n",
       "adaboost_classifier.random_forest_classifier_sc...  0.823706\n",
       "adaboost_classifier.random_forest_classifier_sc...  0.823046\n",
       "adaboost_classifier.extra_trees_classifier_scal...  0.822949\n",
       "adaboost_classifier.extra_trees_classifier_scal...  0.822921\n",
       "adaboost_classifier.random_forest_classifier_sc...  0.822868\n",
       "adaboost_classifier.extra_trees_classifier_scal...  0.822271\n",
       "adaboost_classifier.recursive_feature_eliminati...  0.820927"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd.sort_values(by='AUC', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k_nearest_neighbors.random_forest_classifier_scaled.smenn</th>\n",
       "      <td>0.579293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision_tree.recursive_feature_elimination_scaled.smenn</th>\n",
       "      <td>0.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision_tree.extra_trees_classifier_scaled.tomek</th>\n",
       "      <td>0.577728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision_tree.random_forest_classifier_scaled.smenn</th>\n",
       "      <td>0.574562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision_tree.extra_trees_classifier_scaled.smenn</th>\n",
       "      <td>0.572037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision_tree.random_forest_classifier_scaled.tomek</th>\n",
       "      <td>0.571528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k_nearest_neighbors.extra_trees_classifier_scaled.tomek</th>\n",
       "      <td>0.565892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k_nearest_neighbors.random_forest_classifier_scaled.tomek</th>\n",
       "      <td>0.564162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k_nearest_neighbors.recursive_feature_elimination_scaled.tomek</th>\n",
       "      <td>0.563206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k_nearest_neighbors.recursive_feature_addition_scaled.tomek</th>\n",
       "      <td>0.558301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         AUC\n",
       "k_nearest_neighbors.random_forest_classifier_sc...  0.579293\n",
       "decision_tree.recursive_feature_elimination_sca...  0.578125\n",
       "decision_tree.extra_trees_classifier_scaled.tomek   0.577728\n",
       "decision_tree.random_forest_classifier_scaled.s...  0.574562\n",
       "decision_tree.extra_trees_classifier_scaled.smenn   0.572037\n",
       "decision_tree.random_forest_classifier_scaled.t...  0.571528\n",
       "k_nearest_neighbors.extra_trees_classifier_scal...  0.565892\n",
       "k_nearest_neighbors.random_forest_classifier_sc...  0.564162\n",
       "k_nearest_neighbors.recursive_feature_eliminati...  0.563206\n",
       "k_nearest_neighbors.recursive_feature_addition_...  0.558301"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd.sort_values(by='AUC', ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model tốt nhất: adaboost_classifier\n",
    "- Features tốt nhất: recursive_feature_elimination_scaled\n",
    "- resample tốt nhất: tomek, or enn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4769b5f4808649e9f6efc2edf9fbe2018aef5c0a679de8e6bc3eb348403e35b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
