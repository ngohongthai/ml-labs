{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Phần Nâng cao - Cải tiến mô hình\n",
    "\n",
    "Phần này học viên sẽ tự thực hiện việc cải tiến kết quả dự đoán của mô hình để cho ra kết quả tốt hơn ở phần trước. Tức là điểm số trên Kaggle của học viên phải vượt qua **0.8246 (Public Score), > top 50%**. Một vài phương pháp được đề xuất để học viên lựa chọn là:\n",
    "\n",
    "- Thay đổi phương pháp lựa chọn đặc trưng để chọn ra bộ đặc trưng tốt hơn\n",
    "\n",
    "- Sử dụng phương pháp khác để xử lý vấn đề mất cân bằng dữ liệu\n",
    "\n",
    "- Sử dụng các mô hình học máy khác hoặc các kỹ thuật kết hợp mô hình nâng cao \n",
    "\n",
    "- Tập trung vào việc cải tiến các mô hình Boosting\n",
    "\n",
    "- Tinh chỉnh các tham số của mô hình\n",
    "\n",
    "- Sử dụng các kỹ thuật K-Fold hoặc chia nhỏ tập train để tránh hiện tượng Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load các package cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "test_id = test['ID']\n",
    "X_train = train.drop('ID', axis=1)\n",
    "X_test = test.drop('ID', axis=1)\n",
    "\n",
    "X_train = X_train.drop('TARGET', axis=1)\n",
    "y_train = train['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khám phá dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76020, 369), (76020,), (75818, 369))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var3', 'var15', 'imp_ent_var16_ult1', 'imp_op_var39_comer_ult1',\n",
       "       'imp_op_var39_comer_ult3', 'imp_op_var40_comer_ult1',\n",
       "       'imp_op_var40_comer_ult3', 'imp_op_var40_efect_ult1',\n",
       "       'imp_op_var40_efect_ult3', 'imp_op_var40_ult1',\n",
       "       ...\n",
       "       'saldo_medio_var29_ult3', 'saldo_medio_var33_hace2',\n",
       "       'saldo_medio_var33_hace3', 'saldo_medio_var33_ult1',\n",
       "       'saldo_medio_var33_ult3', 'saldo_medio_var44_hace2',\n",
       "       'saldo_medio_var44_hace3', 'saldo_medio_var44_ult1',\n",
       "       'saldo_medio_var44_ult3', 'var38'],\n",
       "      dtype='object', length=369)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "numerical_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_features = X_train.select_dtypes(include=[np.object]).columns\n",
    "categories_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73012\n",
       "1     3008\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0395685345961589"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio = y_train.value_counts()[1] / y_train.value_counts().sum()\n",
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi khám phá nhận thấy:\n",
    "- Dữ liệu toàn bộ là các dữ liệu số\n",
    "- Không có dữ liệu bị khuyết\n",
    "- Là imbalanced data do có 73012 target là 0 trong khi chỉ có 3008 target là 1 chiếm tỉ lệ 3,9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loại bỏ các biến trùng, hoặc gần giống nhau, hoặc có tương quan cao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from feature_engine.selection import (\n",
    "    DropConstantFeatures,\n",
    "    DropDuplicateFeatures,\n",
    "    SmartCorrelatedSelection,\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('constant', DropConstantFeatures(tol=0.998)),\n",
    "    ('duplicated', DropDuplicateFeatures()),\n",
    "    ('correlation', SmartCorrelatedSelection(selection_method='variance')),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train)\n",
    "X_train = pipe.transform(X_train)\n",
    "X_test = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76020, 81), (75818, 81))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all features columns\n",
    "selected_features = {}\n",
    "#selected_features['all_features'] = X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_selection(X_train, y_train):\n",
    "    from sklearn.ensemble import ExtraTreesClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from feature_engine.selection import RecursiveFeatureElimination\n",
    "    from feature_engine.selection import RecursiveFeatureAddition\n",
    "    #All features\n",
    "    selected_features = {}\n",
    "    #selected_features['all_features'] = X_train.columns.to_list()\n",
    "    #print('All features: ', len(selected_features['all_features']))\n",
    "    \n",
    "    # ExtraTreesClassifier\n",
    "    # clf = ExtraTreesClassifier(random_state=0)\n",
    "    # clf.fit(X_train, y_train)\n",
    "    # fs = SelectFromModel(estimator=clf , prefit=True)\n",
    "    # selected\n",
    "    # _features['extra_trees_classifier'] = X_train.columns[fs.get_support()].tolist()\n",
    "    \n",
    "    # ExtraTreesClassifier\n",
    "    sel = SelectFromModel(ExtraTreesClassifier(random_state=0))\n",
    "    sel.fit(X_train, y_train)\n",
    "    selected_features['extra_trees_classifier'] = X_train.columns[sel.get_support()].tolist()\n",
    "    print('{} features selected by ExtraTreesClassifier'.format(len(selected_features['extra_trees_classifier'])))\n",
    "    \n",
    "    # RandomForestClassifier\n",
    "    sel = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=10))\n",
    "    sel.fit(X_train, y_train)\n",
    "    selected_features['random_forest_classifier'] = X_train.columns[sel.get_support()].tolist()\n",
    "    print('{} features selected by RandomForestClassifier'.format(len(selected_features['random_forest_classifier'])))\n",
    "\n",
    "    # RecursiveFeatureElimination\n",
    "    model = GradientBoostingClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=2,\n",
    "    random_state=10)\n",
    "    sel = RecursiveFeatureElimination(\n",
    "        variables=None, # automatically evaluate all numerical variables\n",
    "        estimator = model, # the ML model\n",
    "        scoring = 'roc_auc', # the metric we want to evalute\n",
    "        threshold = 0.0005, # the maximum performance drop allowed to remove a feature\n",
    "        cv=2,) # cross-validation\n",
    "    sel.fit(X_train, y_train)\n",
    "    selected_features['recursive_feature_elimination'] = sel.transform(X_train).columns.tolist()\n",
    "    print('{} features selected by RecursiveFeatureElimination'.format(len(selected_features['recursive_feature_elimination'])))\n",
    "    \n",
    "    # RecursiveFeatureAddition\n",
    "    model = GradientBoostingClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=2,\n",
    "    random_state=10)\n",
    "    # Setup the RFA selector\n",
    "    sel = RecursiveFeatureAddition(\n",
    "        variables=None,  # automatically evaluate all numerical variables\n",
    "        estimator=model,  # the ML model\n",
    "        scoring='roc_auc',  # the metric we want to evalute\n",
    "        threshold=0.0005,  # the minimum performance increase needed to select a feature\n",
    "        cv=2)  # cross-validation\n",
    "    sel.fit(X_train, y_train)\n",
    "    selected_features['recursive_feature_addition'] = sel.transform(X_train).columns.tolist()\n",
    "    print('{} features selected by RecursiveFeatureAddition'.format(len(selected_features['recursive_feature_addition'])))\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 features selected by ExtraTreesClassifier\n",
      "12 features selected by RandomForestClassifier\n",
      "6 features selected by RecursiveFeatureElimination\n",
      "4 features selected by RecursiveFeatureAddition\n"
     ]
    }
   ],
   "source": [
    "selected_features = features_selection(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value:  ['var15', 'saldo_var5', 'saldo_var30', 'saldo_var42', 'var36', 'num_var22_hace2', 'num_var22_hace3', 'num_var22_ult3', 'num_var45_hace3', 'num_var45_ult3', 'saldo_medio_var5_hace2', 'saldo_medio_var5_hace3', 'saldo_medio_var5_ult3', 'var38']\n",
      "Value:  ['var15', 'saldo_var5', 'saldo_var30', 'saldo_var42', 'num_var22_hace2', 'num_var22_ult3', 'num_var45_hace3', 'num_var45_ult3', 'saldo_medio_var5_hace2', 'saldo_medio_var5_hace3', 'saldo_medio_var5_ult3', 'var38']\n",
      "Value:  ['var15', 'imp_op_var39_efect_ult3', 'saldo_var30', 'num_var22_ult1', 'saldo_medio_var5_hace3', 'var38']\n",
      "Value:  ['var15', 'saldo_var30', 'saldo_medio_var5_hace3', 'var38']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data = {}\n",
    "\n",
    "for key, value in selected_features.items():\n",
    "    print('Value: ', value)\n",
    "    scaled_data[key+'_scaled'] = {'train': scaler.fit_transform(X_train[value]), 'test': scaler.transform(X_test[value])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.under_sampling import (\n",
    "    RandomUnderSampler,\n",
    "    CondensedNearestNeighbour,\n",
    "    TomekLinks,\n",
    "    OneSidedSelection,\n",
    "    EditedNearestNeighbours,\n",
    "    RepeatedEditedNearestNeighbours,\n",
    "    AllKNN,\n",
    "    NeighbourhoodCleaningRule,\n",
    "    NearMiss,\n",
    "    InstanceHardnessThreshold\n",
    ")\n",
    "\n",
    "undersampler_dict = {\n",
    "    'random': RandomUnderSampler(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        replacement=False),\n",
    "\n",
    "    'tomek': TomekLinks(\n",
    "        sampling_strategy='auto',\n",
    "        n_jobs=n_jobs),\n",
    "\n",
    "    'enn': EditedNearestNeighbours(\n",
    "        sampling_strategy='auto',\n",
    "        n_neighbors=3,\n",
    "        kind_sel='all',\n",
    "        n_jobs=n_jobs),\n",
    "\n",
    "    'allknn': AllKNN(\n",
    "        sampling_strategy='auto',\n",
    "        n_neighbors=3,\n",
    "        kind_sel='all',\n",
    "        n_jobs=n_jobs),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import (\n",
    "    RandomOverSampler,\n",
    "    SMOTE,\n",
    "    ADASYN,\n",
    "    BorderlineSMOTE,\n",
    "    SVMSMOTE,\n",
    ")\n",
    "\n",
    "oversampler_dict = {\n",
    "    'smote': SMOTE(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        k_neighbors=5,\n",
    "        n_jobs=n_jobs),\n",
    "\n",
    "    'border1': BorderlineSMOTE(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        k_neighbors=5,\n",
    "        m_neighbors=10,\n",
    "        kind='borderline-1',\n",
    "        n_jobs=n_jobs),\n",
    "\n",
    "    'adasyn': ADASYN(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        n_neighbors=5,\n",
    "        n_jobs=n_jobs),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-Under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "combined_sampler_dict = {\n",
    "    'smenn': SMOTEENN(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        smote=SMOTE(sampling_strategy='auto', random_state=0, k_neighbors=5),\n",
    "        enn=EditedNearestNeighbours(\n",
    "            sampling_strategy='auto', n_neighbors=3, kind_sel='all'),\n",
    "        n_jobs=n_jobs),\n",
    "\n",
    "    'smtomek': SMOTETomek(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=0,\n",
    "        smote=SMOTE(sampling_strategy='auto', random_state=0, k_neighbors=5),\n",
    "        tomek=TomekLinks(sampling_strategy='all'),\n",
    "        n_jobs=n_jobs),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huấn luyện các mô hình cơ sở"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libs\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import  AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemle_models = {\n",
    "    'adaboost_classifier': AdaBoostClassifier(),\n",
    "    'gradientboost_classifier': GradientBoostingClassifier(),\n",
    "    'xgboost_classifier': XGBClassifier(missing=np.nan, max_depth=5, n_estimators=350, \n",
    "                     learning_rate=0.03, nthread=4, subsample=0.95, \n",
    "                     colsample_bytree=0.85, seed=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_model(model, X_train, y_train, resampler):\n",
    "    pipeline = make_pipeline(resampler, model)\n",
    "    cv_results =  cross_validate(pipeline, \n",
    "                                 X_train, \n",
    "                                 y_train, \n",
    "                                 cv=3, \n",
    "                                 scoring='roc_auc', \n",
    "                                 n_jobs=n_jobs,)\n",
    "    return cv_results['test_score'].mean(), cv_results['test_score'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Model:  adaboost_classifier\n",
      "========================================\n",
      "__Dataset: extra_trees_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.818 +/- 0.004\n",
      "________Max AUC: 0.818 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.823 +/- 0.004\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.823 +/- 0.006\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.822 +/- 0.006\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: smote\n",
      "________AUC: 0.817 +/- 0.006\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: border1\n",
      "________AUC: 0.815 +/- 0.004\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.816 +/- 0.007\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.809 +/- 0.003\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.816 +/- 0.006\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Dataset: random_forest_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.819 +/- 0.005\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.823 +/- 0.005\n",
      "________Max AUC: 0.823 (model: adaboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: enn\n",
      "________AUC: 0.824 +/- 0.005\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.823 +/- 0.004\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: smote\n",
      "________AUC: 0.813 +/- 0.007\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: border1\n",
      "________AUC: 0.815 +/- 0.004\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.811 +/- 0.007\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.800 +/- 0.004\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.812 +/- 0.006\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Dataset: recursive_feature_elimination_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.821 +/- 0.003\n",
      "________Max AUC: 0.824 (model: adaboost_classifier, dataset: random_forest_classifier_scaled, resampler: enn)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.825 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.825 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.824 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.814 +/- 0.001\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.815 +/- 0.003\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.816 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.799 +/- 0.003\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.814 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Dataset: recursive_feature_addition_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.816 +/- 0.005\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.821 +/- 0.004\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.820 +/- 0.004\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.820 +/- 0.003\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.812 +/- 0.003\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.811 +/- 0.001\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.813 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.795 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.813 +/- 0.002\n",
      "________Max AUC: 0.825 (model: adaboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "========================================\n",
      "Model:  gradientboost_classifier\n",
      "========================================\n",
      "__Dataset: extra_trees_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.828 +/- 0.005\n",
      "________Max AUC: 0.828 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: random)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.830 +/- 0.006\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.830 +/- 0.006\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: enn)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.830 +/- 0.005\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: smote\n",
      "________AUC: 0.821 +/- 0.004\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: border1\n",
      "________AUC: 0.823 +/- 0.001\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.819 +/- 0.005\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.818 +/- 0.004\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.820 +/- 0.004\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Dataset: random_forest_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.828 +/- 0.006\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.829 +/- 0.006\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: enn\n",
      "________AUC: 0.829 +/- 0.005\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.828 +/- 0.005\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: smote\n",
      "________AUC: 0.819 +/- 0.007\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: border1\n",
      "________AUC: 0.820 +/- 0.003\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.818 +/- 0.007\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.809 +/- 0.004\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.818 +/- 0.006\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Dataset: recursive_feature_elimination_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.829 +/- 0.003\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: extra_trees_classifier_scaled, resampler: allknn)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.830 +/- 0.004\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.829 +/- 0.003\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.829 +/- 0.003\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.825 +/- 0.002\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.823 +/- 0.002\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.825 +/- 0.003\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.803 +/- 0.004\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.826 +/- 0.002\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Dataset: recursive_feature_addition_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.822 +/- 0.004\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.824 +/- 0.004\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.824 +/- 0.004\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.823 +/- 0.004\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.820 +/- 0.004\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.818 +/- 0.002\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.820 +/- 0.003\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.795 +/- 0.004\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.820 +/- 0.003\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "========================================\n",
      "Model:  xgboost_classifier\n",
      "========================================\n",
      "__Dataset: extra_trees_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.828 +/- 0.006\n",
      "________Max AUC: 0.830 (model: gradientboost_classifier, dataset: recursive_feature_elimination_scaled, resampler: tomek)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.833 +/- 0.006\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.833 +/- 0.006\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.832 +/- 0.006\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.813 +/- 0.003\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.819 +/- 0.003\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.812 +/- 0.003\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.818 +/- 0.004\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.815 +/- 0.003\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Dataset: random_forest_classifier_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.827 +/- 0.007\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.832 +/- 0.006\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.832 +/- 0.006\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.831 +/- 0.005\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.814 +/- 0.004\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.819 +/- 0.001\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.812 +/- 0.005\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.810 +/- 0.002\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.814 +/- 0.004\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Dataset: recursive_feature_elimination_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.826 +/- 0.003\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.831 +/- 0.003\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.831 +/- 0.003\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.830 +/- 0.004\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.816 +/- 0.004\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.819 +/- 0.001\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.815 +/- 0.005\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.797 +/- 0.005\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.818 +/- 0.003\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Dataset: recursive_feature_addition_scaled\n",
      "__Resampler: random\n",
      "________AUC: 0.820 +/- 0.004\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: tomek\n",
      "________AUC: 0.825 +/- 0.004\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: enn\n",
      "________AUC: 0.824 +/- 0.004\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: allknn\n",
      "________AUC: 0.824 +/- 0.003\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: smote\n",
      "________AUC: 0.809 +/- 0.005\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: border1\n",
      "________AUC: 0.814 +/- 0.002\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: adasyn\n",
      "________AUC: 0.807 +/- 0.006\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: smenn\n",
      "________AUC: 0.781 +/- 0.001\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n",
      "__Resampler: smtomek\n",
      "________AUC: 0.813 +/- 0.004\n",
      "________Max AUC: 0.833 (model: xgboost_classifier, dataset: extra_trees_classifier_scaled, resampler: tomek)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_dict = {}\n",
    "std_dict = {}\n",
    "\n",
    "max_score = 0\n",
    "max_model_name = ''\n",
    "max_dataset_name = ''\n",
    "max_resampler_name = ''\n",
    "\n",
    "for model_name, model in ensemle_models.items():\n",
    "    results_dict[model_name] = {}\n",
    "    std_dict[model_name] = {}\n",
    "    print(\"=\"*40)\n",
    "    print('Model: ', model_name)\n",
    "    print(\"=\"*40)\n",
    "    for dataset_name, dataset in scaled_data.items():\n",
    "        \n",
    "        results_dict[model_name][dataset_name] = {}\n",
    "        std_dict[model_name][dataset_name] = {}\n",
    "        \n",
    "        print('__Dataset: {}'.format(dataset_name))\n",
    "        \n",
    "        X_train = dataset['train']\n",
    "        \n",
    "        for resampler_name, resampler in undersampler_dict.items():\n",
    "            print('__Resampler: {}'.format(resampler_name))\n",
    "            auc, auc_std = run_model(model, X_train, y_train, resampler)\n",
    "            print('________AUC: {:.3f} +/- {:.3f}'.format(auc, auc_std))\n",
    "            results_dict[model_name][dataset_name][resampler_name] = auc\n",
    "            std_dict[model_name][dataset_name][resampler_name] = auc_std\n",
    "            if auc > max_score:\n",
    "                max_score = auc\n",
    "                max_model_name = model_name\n",
    "                max_dataset_name = dataset_name\n",
    "                max_resampler_name = resampler_name\n",
    "            print('________Max AUC: {:.3f} (model: {}, dataset: {}, resampler: {})'.format(max_score, max_model_name, max_dataset_name, max_resampler_name))\n",
    "    \n",
    "        for resampler_name, resampler in oversampler_dict.items():\n",
    "            print('__Resampler: {}'.format(resampler_name))\n",
    "            auc, auc_std = run_model(model, X_train, y_train, resampler)\n",
    "            print('________AUC: {:.3f} +/- {:.3f}'.format(auc, auc_std))\n",
    "            results_dict[model_name][dataset_name][resampler_name] = auc\n",
    "            std_dict[model_name][dataset_name][resampler_name] = auc_std\n",
    "            if auc > max_score:\n",
    "                max_score = auc\n",
    "                max_model_name = model_name\n",
    "                max_dataset_name = dataset_name\n",
    "                max_resampler_name = resampler_name\n",
    "            print('________Max AUC: {:.3f} (model: {}, dataset: {}, resampler: {})'.format(max_score, max_model_name, max_dataset_name, max_resampler_name))\n",
    "        \n",
    "        for resampler_name, resampler in combined_sampler_dict.items():\n",
    "            print('__Resampler: {}'.format(resampler_name))\n",
    "            auc, auc_std = run_model(model, X_train, y_train, resampler)\n",
    "            print('________AUC: {:.3f} +/- {:.3f}'.format(auc, auc_std))\n",
    "            results_dict[model_name][dataset_name][resampler_name] = auc\n",
    "            std_dict[model_name][dataset_name][resampler_name] = auc_std\n",
    "            if auc > max_score:\n",
    "                max_score = auc\n",
    "                max_model_name = model_name\n",
    "                max_dataset_name = dataset_name\n",
    "                max_resampler_name = resampler_name\n",
    "            print('________Max AUC: {:.3f} (model: {}, dataset: {}, resampler: {})'.format(max_score, max_model_name, max_dataset_name, max_resampler_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableMapping\n",
    "\n",
    "def flatten(d, parent_key='', sep='.'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, MutableMapping):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(flatten(results_dict), orient='index', columns=['AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xgboost_classifier.extra_trees_classifier_scaled.tomek</th>\n",
       "      <td>0.833057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost_classifier.extra_trees_classifier_scaled.enn</th>\n",
       "      <td>0.832921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost_classifier.extra_trees_classifier_scaled.allknn</th>\n",
       "      <td>0.832241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost_classifier.random_forest_classifier_scaled.tomek</th>\n",
       "      <td>0.832198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost_classifier.random_forest_classifier_scaled.enn</th>\n",
       "      <td>0.832041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost_classifier.recursive_feature_elimination_scaled.tomek</th>\n",
       "      <td>0.831439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost_classifier.random_forest_classifier_scaled.allknn</th>\n",
       "      <td>0.831138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost_classifier.recursive_feature_elimination_scaled.enn</th>\n",
       "      <td>0.831075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost_classifier.recursive_feature_elimination_scaled.allknn</th>\n",
       "      <td>0.830404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradientboost_classifier.recursive_feature_elimination_scaled.tomek</th>\n",
       "      <td>0.830354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         AUC\n",
       "xgboost_classifier.extra_trees_classifier_scale...  0.833057\n",
       "xgboost_classifier.extra_trees_classifier_scale...  0.832921\n",
       "xgboost_classifier.extra_trees_classifier_scale...  0.832241\n",
       "xgboost_classifier.random_forest_classifier_sca...  0.832198\n",
       "xgboost_classifier.random_forest_classifier_sca...  0.832041\n",
       "xgboost_classifier.recursive_feature_eliminatio...  0.831439\n",
       "xgboost_classifier.random_forest_classifier_sca...  0.831138\n",
       "xgboost_classifier.recursive_feature_eliminatio...  0.831075\n",
       "xgboost_classifier.recursive_feature_eliminatio...  0.830404\n",
       "gradientboost_classifier.recursive_feature_elim...  0.830354"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by='AUC', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đánh gía, thử với tệp test và submit lên Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thử với xgboost_classifier\n",
    "- model: xgboost_classifier\n",
    "- selected feature by: extra_trees_classifier_scaled\n",
    "- resampled model by: tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8803949217952097"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = ensemle_models['xgboost_classifier']\n",
    "X_train = scaled_data['extra_trees_classifier_scaled']['train']\n",
    "X_test = scaled_data['extra_trees_classifier_scaled']['test']\n",
    "resampler = undersampler_dict['tomek']\n",
    "\n",
    "X_train_tomek, y_train_tomek = resampler.fit_resample(X_train, y_train)\n",
    "model.fit(X_train_tomek, y_train_tomek)\n",
    "y_pred = model.predict_proba(X_train_tomek)\n",
    "roc_auc_score(y_train_tomek, y_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": probs[:,1]})\n",
    "submission.to_csv(\"adv_xgboost_classifier_submittion.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kết quả trên Kaggle\n",
    "\n",
    "![](images/my_adv_submittion.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('sklearn-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e5e2e4be1ebd907a801c68ebfc07d1a6416a7e697e27568b05a2a0dea334337"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
