# Feature Engineering for Machine Learning

## Python and packages

```shell
category-encoders>=2.3.0
feature-engine>=1.2.0
numpy>=1.22.2
pandas>=1.4.1
scikit-learn>=1.0.2
scipy>=1.8.0
statsmodels>=0.13.2
```     

In the anaconda prompt:

```shell
conda create -n mynewenv python=3.6 anaconda
activate mynewenv
conda install numpy
conda istall pandas
pip install feature-engine
pip install category-encoders
```

## Code
[Github](https://github.com/solegalli/feature-engineering-for-machine-learning)

## Download House Prices dataset from Kaggle

### Create a Kaggle account.

- Visit [Kaggle's website](https://www.kaggle.com/).
- Click on the "Create an account" button and follow the instructions to set up your account.
  
### Download data set.

- Visit the [House Sale Price competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) website, scroll down and click on train.csv.zip and then on the download button on the right.
- Unzip the content.
- Rename the data set to **houseprice.csv**.

## Feature-Engineering-Course-Presentations

- [Dropbox](https://www.dropbox.com/sh/2vtm7k5maiyqrob/AAD7fm7Xwk6Ye9G54pgFRdFea?dl=0)

## Linear model assumptions - additional reading resources

- [7 Classical Assumptions of OLS Linear Regression](https://statisticsbyjim.com/regression/ols-linear-regression-assumptions/)

- [The 4 Assumptions of Linear Regression](https://www.statology.org/linear-regression-assumptions/)

- [The Distribution of Independent Variables in Linear Models](https://www.theanalysisfactor.com/the-distribution-of-independent-variables-in-regression-models-2/)

## Section 3 - Variable Characteristics - Additional reading resources

### Overview of variable characteristics
- [Identifying common Data Mining Mistakes by SAS](https://www.mwsug.org/proceedings/2007/saspres/MWSUG-2007-SAS01.pdf)
### Missing data
- [Missing data imputation, chapter 25](http://www.stat.columbia.edu/~gelman/arm/missing.pdf)
### Linear and non-linear models
- [An introduction to Statistical Learning](http://faculty.marshall.usc.edu/gareth-james/)
- [Elements of Statistical Learning](http://faculty.marshall.usc.edu/gareth-james/)
### Q-Q plots
- [Q-Q Plots in wiki](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot)
- [How to interpret a Q-Q plot](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot)
- [Q-Q Plot visualisation tool](https://xiongge.shinyapps.io/QQplots/)
### Outliers
- [Why is AdaBoost algorithm sensitive to noisy data and outliers?](https://www.quora.com/unanswered/Why-is-AdaBoost-algorithm-sensitive-to-noisy-data-and-outliers-And-how)
- [Why is Logistic Regression robust to outliers compared to least squares?](https://www.quora.com/Why-is-logistic-regression-considered-robust-to-outliers-compared-to-a-least-square-method)
- [Can Logistic Regression be considered robust to outliers?](https://www.quora.com/unanswered/Can-Logistic-Regression-be-considered-robust-to-outliers)
- [The Effects of Outlier Data on Neural Networks Performance](https://www.researchgate.net/profile/Azme-Khamis/publication/26568300_The_Effects_of_Outliers_Data_on_Neural_Network_Performance/links/564802c908ae54697fbc10de/The-Effects-of-Outliers-Data-on-Neural-Network-Performance.pdf)
- [Outlier Analysis by C. Aggarwal](http://charuaggarwal.net/outlierbook.pdf)
### Feature scaling
- [Should I normalize/standardize/rescale the data?](http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html)
- [Efficient BackProp by Yann LeCun](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)
- [Standardization and Its Effects on K -Means Clustering Algorithm](https://maxwellsci.com/print/rjaset/v6-3299-3303.pdf)
- [Feature scaling in support vector data description](http://rduin.nl/papers/asci_02_occ.pdf)
### Overview of machine learning algorithms
- [Top 10 Machine Learning Algorithms](https://www.dezyre.com/article/top-10-machine-learning-algorithms/202)
- [Choosing the Right Algorithm for Machine Learning](https://www.dummies.com/article/technology/information-technology/ai/machine-learning/choosing-right-algorithm-machine-learning-221423/)
- [Why does Gradient boosting work so well for so many Kaggle problems?](https://www.quora.com/Why-does-Gradient-boosting-work-so-well-for-so-many-Kaggle-problems)
### Kaggle kernels
- Titanic dataset
  - [Exploring Survival on the Titanic](https://www.kaggle.com/code/mrisdal/exploring-survival-on-the-titanic/report)
  - [Titanic Data Science Solutions](https://www.kaggle.com/code/startupsci/titanic-data-science-solutions/notebook)
- House Sales Price dataset
  - [Comprehensive Data Exploration](https://www.kaggle.com/code/pmarcelino/comprehensive-data-exploration-with-python/notebook)